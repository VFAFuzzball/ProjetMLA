{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff95ff06-4bdf-4e22-8b2b-ec3ffed114f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 2.81 ms (started: 2022-12-22 21:25:53 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from fgsm import  get_adversarial_exemple \n",
    "\n",
    "%load_ext tensorboard\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912aeef2-a400-4c3b-9e25-0790ebce672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 21:15:23.705420: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-22 21:15:23.705488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-12-22 21:15:23.706145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 220 ms (started: 2022-12-22 21:15:23 +01:00)\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898720a8-ebe9-433b-aa8c-70fe30d9149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.57 s (started: 2022-12-22 21:20:10 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# convert tf.data.Dataset to numpy array\n",
    "x_test = np.concatenate([x for x, y in ds_test], axis=0)\n",
    "y_test = np.concatenate([y for x, y in ds_test], axis=0)\n",
    "x_train = np.concatenate([x for x, y in ds_train], axis=0)\n",
    "y_train = np.concatenate([y for x, y in ds_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a69f07-a836-4747-982a-41619ae5ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.18 ms (started: 2022-12-22 21:15:23 +01:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SequentialAdversarialLoss(tf.keras.Sequential):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(SequentialAdversarialLoss, self).__init__(*args, **kwargs)\n",
    "        self.alpha = 0.5\n",
    "        self.a = []\n",
    "        self.eps = 0.25\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "        \"\"\"for i in x:\n",
    "            print(x)\n",
    "        print(tf.identity(x))\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((tf.expand_dims(tf.identity(x),0),tf.expand_dims(tf.identity(y),0)))\n",
    "        print(dataset)\n",
    "        print(\"-------------------\")\n",
    "        adv_x = get_adversarial_exemple(self,dataset,0.25)\n",
    "        print(\"++++++++++++++++++++++\")\"\"\"\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            #tape.watch(adv_x)\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            \n",
    "            #adv_y_pred = self(adv_x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "            \n",
    "        gradient = tape.gradient(loss, x)\n",
    "        signed_grad = tf.sign(gradient)\n",
    "        x_adv = x + 0.25 * signed_grad\n",
    "        x_adv = tf.clip_by_value(x_adv, 0, 1)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x_adv)\n",
    "            y_pred_adv = self(x_adv, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss *= self.alpha \n",
    "            loss += (1 - self.alpha) * self.compiled_loss(y, y_pred_adv)\n",
    "            \n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        del tape\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9686225-9f58-4781-955d-1d22cb5f7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 13s 24ms/step - loss: 1.3279 - accuracy: 0.7286\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 1.0089 - accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.9041 - accuracy: 0.8744\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.8366 - accuracy: 0.8917\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.7928 - accuracy: 0.8974\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.7617 - accuracy: 0.9017\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.7292 - accuracy: 0.9098\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.7053 - accuracy: 0.9132\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6848 - accuracy: 0.9154\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6657 - accuracy: 0.9186\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.6508 - accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6355 - accuracy: 0.9214\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6241 - accuracy: 0.9257\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6093 - accuracy: 0.9242\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.5856 - accuracy: 0.9234\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5729 - accuracy: 0.9251\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5599 - accuracy: 0.9257\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5556 - accuracy: 0.9275\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5554 - accuracy: 0.9295\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5601 - accuracy: 0.9294\n",
      "------------------Train dataset-------------\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1267 - accuracy: 0.9649\n",
      "Accuracy on adversarial examples: 0.0994499996304512 \n",
      " with a mean confidence of 0.722237765789032\n",
      "------------------Test dataset-------------\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1233 - accuracy: 0.9648\n",
      "Accuracy on adversarial examples: 0.541700005531311 \n",
      " with a mean confidence of 0.7293791770935059\n",
      "time: 4min 26s (started: 2022-12-22 21:20:17 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Shallow maxout model inspired from https://github.com/philipperemy/tensorflow-maxout/blob/master/mnist_maxout_example.py\n",
    "\n",
    "shallow_maxout = SequentialAdversarialLoss([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "shallow_maxout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "shallow_maxout.fit(ds_train, epochs=20)\n",
    "\n",
    "print(\"------------------Train dataset-------------\")\n",
    "shallow_maxout.evaluate(ds_train) \n",
    "x_train_adv = get_adversarial_exemple(shallow_maxout, ds_train, eps=0.25)\n",
    "_, accuracy =  shallow_maxout.evaluate(x_train_adv, y_train, verbose = 0)\n",
    "confidence = np.mean(np.max(shallow_maxout.predict(x_train_adv, verbose = 0), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )\n",
    "print(\"------------------Test dataset-------------\")\n",
    "shallow_maxout.evaluate(ds_test) \n",
    "x_test_adv = get_adversarial_exemple(shallow_maxout, ds_test, eps=0.25)\n",
    "loss, accuracy =  shallow_maxout.evaluate(x_test_adv, y_test, verbose = 0)\n",
    "confidence = np.mean(np.max(shallow_maxout.predict(x_test_adv, verbose = 0), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257a4e48-77cd-45d2-ac95-8a15d4ea288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 8s 15ms/step - loss: 0.4303 - accuracy: 0.8658\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1979 - accuracy: 0.9419\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1567 - accuracy: 0.9543\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1382 - accuracy: 0.9585\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1212 - accuracy: 0.9644\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1160 - accuracy: 0.9658\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1084 - accuracy: 0.9681\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1004 - accuracy: 0.9705\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0951 - accuracy: 0.9715\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0923 - accuracy: 0.9729\n",
      "------------------Train dataset-------------\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0324 - accuracy: 0.9901\n",
      "Accuracy on adversarial examples: 0.09803333133459091\n",
      "------------------Test dataset-------------\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9782\n",
      "Accuracy on adversarial examples: 0.09030000120401382\n",
      "time: 1min 39s (started: 2022-12-22 21:25:56 +01:00)\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "shallow_maxout = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "shallow_maxout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "shallow_maxout.fit(ds_train, epochs=10,callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"------------------Train dataset-------------\")\n",
    "shallow_maxout.evaluate(ds_train) \n",
    "x_train_adv = get_adversarial_exemple(shallow_maxout, ds_train, eps=0.25)\n",
    "_, accuracy =  shallow_maxout.evaluate(x_train_adv, y_train, verbose = 0)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy}\")\n",
    "#confidence = np.mean(np.max(shallow_maxout.predict(x_train_adv, verbose = 0), axis=1))\n",
    "#print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )\n",
    "\n",
    "print(\"------------------Test dataset-------------\")\n",
    "shallow_maxout.evaluate(ds_test) \n",
    "x_test_adv = get_adversarial_exemple(shallow_maxout, ds_test, eps=0.25)\n",
    "loss, accuracy =  shallow_maxout.evaluate(x_test_adv, y_test, verbose = 0)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy}\")\n",
    "#confidence = np.mean(np.max(shallow_maxout.predict(x_test_adv, verbose = 0), axis=1))\n",
    "#print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7242f1d-bab9-49a5-8045-8c6d4cd3a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir='logs/scalars'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
