{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff95ff06-4bdf-4e22-8b2b-ec3ffed114f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 23:27:12.988740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 23:27:14.190897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 23:27:14.191044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 23:27:14.191060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 900 Âµs (started: 2022-12-22 23:27:16 +01:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdel/.local/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from fgsm import  get_adversarial_exemple \n",
    "\n",
    "%load_ext tensorboard\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912aeef2-a400-4c3b-9e25-0790ebce672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 23:27:16.428171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-22 23:27:16.428242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-12-22 23:27:16.429075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 221 ms (started: 2022-12-22 23:27:16 +01:00)\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898720a8-ebe9-433b-aa8c-70fe30d9149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.26 s (started: 2022-12-22 23:27:16 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# convert tf.data.Dataset to numpy array\n",
    "x_test = np.concatenate([x for x, y in ds_test], axis=0)\n",
    "y_test = np.concatenate([y for x, y in ds_test], axis=0)\n",
    "x_train = np.concatenate([x for x, y in ds_train], axis=0)\n",
    "y_train = np.concatenate([y for x, y in ds_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a69f07-a836-4747-982a-41619ae5ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms (started: 2022-12-22 23:27:21 +01:00)\n"
     ]
    }
   ],
   "source": [
    "class SequentialAdversarialLoss(tf.keras.Sequential):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(SequentialAdversarialLoss, self).__init__(*args, **kwargs)\n",
    "        self.alpha = 0.5\n",
    "        self.a = []\n",
    "        self.eps = 0.25\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            #tape.watch(adv_x)\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            \n",
    "            #adv_y_pred = self(adv_x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "            \n",
    "        gradient = tape.gradient(loss, x)\n",
    "        signed_grad = tf.sign(gradient)\n",
    "        x_adv = x + 0.25 * signed_grad\n",
    "        x_adv = tf.clip_by_value(x_adv, 0, 1)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x_adv)\n",
    "            y_pred_adv = self(x_adv, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss *= self.alpha \n",
    "            loss += (1 - self.alpha) * self.compiled_loss(y, y_pred_adv)\n",
    "            \n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        del tape\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9686225-9f58-4781-955d-1d22cb5f7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 14s 26ms/step - loss: 1.3239 - accuracy: 0.7324\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.0056 - accuracy: 0.8506\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.8989 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.8334 - accuracy: 0.8895\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.7829 - accuracy: 0.9005\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.7525 - accuracy: 0.9038\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.7296 - accuracy: 0.9089\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.6976 - accuracy: 0.9154\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.6892 - accuracy: 0.9166\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.6670 - accuracy: 0.9203\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.6499 - accuracy: 0.9216\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6422 - accuracy: 0.9239\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.6304 - accuracy: 0.9247\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.6217 - accuracy: 0.9268\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.6163 - accuracy: 0.9273\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.6034 - accuracy: 0.9290\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.5930 - accuracy: 0.9316\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.5927 - accuracy: 0.9323\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.5861 - accuracy: 0.9321\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5818 - accuracy: 0.9333\n",
      "------------------Train dataset-------------\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9669\n",
      "Accuracy on adversarial examples: 0.10083333402872086 \n",
      " with a mean confidence of 0.678969144821167\n",
      "------------------Test dataset-------------\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.9670\n",
      "Accuracy on adversarial examples: 0.5266000032424927 \n",
      " with a mean confidence of 0.6900075078010559\n",
      "time: 4min 34s (started: 2022-12-22 23:27:21 +01:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "maxout = SequentialAdversarialLoss([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "maxout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "maxout.fit(ds_train, epochs=20)\n",
    "\n",
    "print(\"------------------Train dataset-------------\")\n",
    "maxout.evaluate(ds_train) \n",
    "x_train_adv = get_adversarial_exemple(maxout, ds_train, eps=0.25)\n",
    "_, accuracy =  maxout.evaluate(x_train_adv, y_train, verbose = 0)\n",
    "confidence = np.mean(np.max(maxout.predict(x_train_adv, verbose = 0), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )\n",
    "print(\"------------------Test dataset-------------\")\n",
    "maxout.evaluate(ds_test) \n",
    "x_test_adv = get_adversarial_exemple(maxout, ds_test, eps=0.25)\n",
    "loss, accuracy =  maxout.evaluate(x_test_adv, y_test, verbose = 0)\n",
    "confidence = np.mean(np.max(maxout.predict(x_test_adv, verbose = 0), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257a4e48-77cd-45d2-ac95-8a15d4ea288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 8s 15ms/step - loss: 0.4445 - accuracy: 0.8636\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1955 - accuracy: 0.9424\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1589 - accuracy: 0.9539\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1343 - accuracy: 0.9603\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1248 - accuracy: 0.9633\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1136 - accuracy: 0.9657\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1050 - accuracy: 0.9695\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.1013 - accuracy: 0.9701\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0920 - accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0897 - accuracy: 0.9732\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0851 - accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0833 - accuracy: 0.9747\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0819 - accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0764 - accuracy: 0.9774\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0762 - accuracy: 0.9776\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0747 - accuracy: 0.9780\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0708 - accuracy: 0.9793\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0705 - accuracy: 0.9793\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0698 - accuracy: 0.9792\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0695 - accuracy: 0.9793\n",
      "------------------Train dataset-------------\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Accuracy on adversarial examples: 0.09806666523218155\n",
      "------------------Test dataset-------------\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9847\n",
      "Accuracy on adversarial examples: 0.2705000042915344\n",
      "time: 2min 55s (started: 2022-12-22 23:40:42 +01:00)\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "maxout = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(960),\n",
    "  tfa.layers.Maxout(240),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(20, activation='softmax'),\n",
    "])\n",
    "\n",
    "maxout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "maxout.fit(ds_train, epochs=20,callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"------------------Train dataset-------------\")\n",
    "maxout.evaluate(ds_train) \n",
    "x_train_adv = get_adversarial_exemple(maxout, ds_train, eps=0.25)\n",
    "_, accuracy =  maxout.evaluate(x_train_adv, y_train, verbose = 0)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy}\")\n",
    "#confidence = np.mean(np.max(maxout.predict(x_train_adv, verbose = 0), axis=1))\n",
    "#print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )\n",
    "\n",
    "print(\"------------------Test dataset-------------\")\n",
    "maxout.evaluate(ds_test) \n",
    "x_test_adv = get_adversarial_exemple(maxout, ds_test, eps=0.25)\n",
    "loss, accuracy =  maxout.evaluate(x_test_adv, y_test, verbose = 0)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy}\")\n",
    "#confidence = np.mean(np.max(maxout.predict(x_test_adv, verbose = 0), axis=1))\n",
    "#print(f\"Accuracy on adversarial examples: {accuracy} \\n with a mean confidence of {confidence}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7242f1d-bab9-49a5-8045-8c6d4cd3a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9ad101d872ac9953\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9ad101d872ac9953\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.54 s (started: 2022-12-22 23:33:37 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir='logs/scalars'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
