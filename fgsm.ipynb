{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bounadja Bilal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Bounadja Bilal\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.40 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.01 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:04<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:05<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:06<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:07<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:07<00:00,  1.01 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:08<00:00,  1.01 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:08<00:00,  2.68s/ url]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:08<00:00,  2.68s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:09<00:00,  2.68s/ url]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:09<00:00,  2.34s/ file]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:09<00:00,  1.07 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:09<00:00,  2.35s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\Bounadja Bilal\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_adversial_exemple(model, image, label, eps=0.25):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(label, prediction)\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    adv_ex = image + eps*signed_grad    \n",
    "    adv_ex = tf.clip_by_value(adv_ex, 0, 1)\n",
    "    return adv_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 2ms/step - loss: 0.6638 - accuracy: 0.8366\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.9030\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9123\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.9168\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9200\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.2784 - accuracy: 0.9225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2783918082714081, 0.9225000143051147]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shallow softmax model\n",
    "\n",
    "shallow_softmax = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "shallow_softmax.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "shallow_softmax.fit(ds_train, epochs=5)\n",
    "shallow_softmax.evaluate(ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3934 - accuracy: 0.8888\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9588\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1051 - accuracy: 0.9689\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9797\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0974089726805687, 0.9718000292778015]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shallow maxout model inspired from https://github.com/philipperemy/tensorflow-maxout/blob/master/mnist_maxout_example.py\n",
    "\n",
    "shallow_maxout = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tfa.layers.Maxout(50),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "shallow_maxout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "shallow_maxout.fit(ds_train, epochs=5)\n",
    "shallow_maxout.evaluate(ds_test) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tf.data.Dataset to numpy array\n",
    "x_test = np.concatenate([x for x, y in ds_test], axis=0)\n",
    "y_test = np.concatenate([y for x, y in ds_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 15.3625 - accuracy: 0.0000e+00\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Accuracy on adversial examples: 0.0 with a mean confidence of 0.8821612596511841\n"
     ]
    }
   ],
   "source": [
    "# avaluate shallow_softmax model on adversarial examples\n",
    "\n",
    "x_test_adv = [get_adversial_exemple(shallow_softmax, x, y,eps=0.25).numpy()[0] for x,y in zip(x_test, y_test)]\n",
    "x_test_adv = np.array(x_test_adv)\n",
    "\n",
    "l,a =  shallow_softmax.evaluate(x_test_adv, y_test)\n",
    "c = np.mean(np.max(shallow_softmax.predict(x_test_adv), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {a} with a mean confidence of {c}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 25.5275 - accuracy: 0.0024\n",
      "313/313 [==============================] - 0s 2ms/step\n",
      "Accuracy on adversial examples: 0.002400000113993883 with a mean confidence of 0.9183363318443298\n"
     ]
    }
   ],
   "source": [
    "# evaluate shallow_maxout model on adversarial examples\n",
    "\n",
    "x_test_adv = [get_adversial_exemple(shallow_maxout, x, y,eps=0.25).numpy()[0] for x,y in zip(x_test, y_test)]\n",
    "x_test_adv = np.array(x_test_adv)\n",
    "\n",
    "l,a =  shallow_maxout.evaluate(x_test_adv, y_test)\n",
    "c = np.mean(np.max(shallow_maxout.predict(x_test_adv), axis=1))\n",
    "print(f\"Accuracy on adversarial examples: {a} with a mean confidence of {c}\", )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1274c6305ed34a388a50a982e0b0cca469956cd66364a19dc680feb882b62437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
