{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://gist.github.com/mrgrhn/a6ad98dbc81f3ec8f73d39415452de9a#file-googlenet_tensorflow-ipynb","timestamp":1671528163229}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CXt05UtlLUcz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671710096876,"user_tz":-60,"elapsed":19921,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}},"outputId":"b80b7df8-cfb6-453d-ae79-4f86d70cc1e4"},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import datasets, layers, models, losses, Model\n","from google.colab import drive\n","import time\n","from PIL import Image\n","import numpy as np\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","!unzip -qq 'tiny-imagenet-200.zip'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BedjJ0CrZgW","executionInfo":{"status":"ok","timestamp":1671710179607,"user_tz":-60,"elapsed":28602,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}},"outputId":"11eddaf5-4b9b-4e9d-a56e-128411b77b9f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-22 11:55:11--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n","Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248100043 (237M) [application/zip]\n","Saving to: ‘tiny-imagenet-200.zip’\n","\n","tiny-imagenet-200.z 100%[===================>] 236.61M  14.8MB/s    in 17s     \n","\n","2022-12-22 11:55:28 (14.0 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n","\n"]}]},{"cell_type":"code","source":["path = '/content/tiny-imagenet-200/'\n","\n","def get_id_dictionary():\n","    id_dict = {}\n","    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n","        id_dict[line.replace('\\n', '')] = i\n","    return id_dict\n","  \n","def get_class_to_id_dict():\n","    id_dict = get_id_dictionary()\n","    all_classes = {}\n","    result = {}\n","    for i, line in enumerate(open( path + 'words.txt', 'r')):\n","        n_id, word = line.split('\\t')[:2]\n","        all_classes[n_id] = word\n","    for key, value in id_dict.items():\n","        result[value] = (key, all_classes[key])      \n","    return result\n","\n","def get_data(id_dict):\n","    print('starting loading data')\n","    train_data, test_data = [], []\n","    train_labels, test_labels = [], []\n","    t = time.time()\n","    for key, value in id_dict.items():\n","        train_data += [np.asarray(Image.open( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i))).convert(\"RGB\")) for i in range(500)]\n","        train_labels_ = np.array([[0]*200]*500)\n","        train_labels_[:, value] = 1\n","        train_labels += train_labels_.tolist()\n","\n","    for line in open( path + 'val/val_annotations.txt'):\n","        img_name, class_id = line.split('\\t')[:2]\n","        test_data.append(np.asarray(Image.open( path + 'val/images/{}'.format(img_name)).convert(\"RGB\")))\n","        test_labels_ = np.array([[0]*200])\n","        test_labels_[0, id_dict[class_id]] = 1\n","        test_labels += test_labels_.tolist()\n","\n","    print('finished loading data, in {} seconds'.format(time.time() - t))\n","\n","    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n","    #return train_data, train_labels, test_data, test_labels\n","  \n","train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n","\n","print( \"train data shape: \",  train_data.shape )\n","print( \"train label shape: \", train_labels.shape )\n","print( \"test data shape: \",   test_data.shape )\n","print( \"test_labels.shape: \", test_labels.shape )\n","\n","def shuffle_data(train_data, train_labels ):\n","    size = len(train_data)\n","    train_idx = np.arange(size)\n","    np.random.shuffle(train_idx)\n","\n","    return train_data[train_idx], train_labels[train_idx]\n","  \n","train_data, train_labels = shuffle_data(train_data, train_labels)\n","\n","# The data, shuffled and split between train and test sets:\n","X_train = train_data\n","Y_train = train_labels\n","X_test = test_data\n","Y_test = test_labels\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","\n","# subtract mean and normalize\n","mean_image = np.mean(X_train, axis=0)\n","X_train -= mean_image\n","X_test -= mean_image\n","X_train /= 128.\n","X_test /= 128.\n","\n","x_train = X_train\n","y_train = Y_train\n","x_val = X_test\n","y_val = Y_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-SW6_q8rmsz","executionInfo":{"status":"ok","timestamp":1671710385810,"user_tz":-60,"elapsed":46411,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}},"outputId":"9bb0b6ed-6597-497c-c8da-6d42b2dd0a39"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["starting loading data\n","finished loading data, in 33.79375076293945 seconds\n","train data shape:  (100000, 64, 64, 3)\n","train label shape:  (100000, 200)\n","test data shape:  (10000, 64, 64, 3)\n","test_labels.shape:  (10000, 200)\n"]}]},{"cell_type":"code","metadata":{"id":"baxvTVSQLcC9"},"source":["(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()\n","x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n","x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n","x_train = tf.expand_dims(x_train, axis=3, name=None)\n","x_test = tf.expand_dims(x_test, axis=3, name=None)\n","x_train = tf.repeat(x_train, 3, axis=3)\n","x_test = tf.repeat(x_test, 3, axis=3)\n","x_val = x_train[-2000:,:,:]\n","y_val = y_train[-2000:]\n","x_train = x_train[:-2000,:,:]\n","y_train = y_train[:-2000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wKcYCdaLcFU","executionInfo":{"status":"ok","timestamp":1671710393077,"user_tz":-60,"elapsed":554,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["def inception(x,\n","              filters_1x1,\n","              filters_3x3_reduce,\n","              filters_3x3,\n","              filters_5x5_reduce,\n","              filters_5x5,\n","              filters_pool):\n","  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n","\n","  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n","  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n","\n","  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n","  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n","\n","  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n","  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n","\n","  return tf.concat([path1, path2, path3, path4], axis=3)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDEI1TMtLcHq","executionInfo":{"status":"ok","timestamp":1671710398268,"user_tz":-60,"elapsed":4219,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["inp = layers.Input(shape=(64, 64, 3))\n","input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(inp)\n","\n","x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","\n","x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n","x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n","\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","\n","x = inception(x,\n","              filters_1x1=64,\n","              filters_3x3_reduce=96,\n","              filters_3x3=128,\n","              filters_5x5_reduce=16,\n","              filters_5x5=32,\n","              filters_pool=32)\n","\n","x = inception(x,\n","              filters_1x1=128,\n","              filters_3x3_reduce=128,\n","              filters_3x3=192,\n","              filters_5x5_reduce=32,\n","              filters_5x5=96,\n","              filters_pool=64)\n","\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","\n","x = inception(x,\n","              filters_1x1=192,\n","              filters_3x3_reduce=96,\n","              filters_3x3=208,\n","              filters_5x5_reduce=16,\n","              filters_5x5=48,\n","              filters_pool=64)\n","\n","aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n","aux1 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n","aux1 = layers.Flatten()(aux1)\n","aux1 = layers.Dense(1024, activation='relu')(aux1)\n","aux1 = layers.Dropout(0.7)(aux1)\n","aux1 = layers.Dense(10, activation='softmax')(aux1)\n","\n","x = inception(x,\n","              filters_1x1=160,\n","              filters_3x3_reduce=112,\n","              filters_3x3=224,\n","              filters_5x5_reduce=24,\n","              filters_5x5=64,\n","              filters_pool=64)\n","\n","x = inception(x,\n","              filters_1x1=128,\n","              filters_3x3_reduce=128,\n","              filters_3x3=256,\n","              filters_5x5_reduce=24,\n","              filters_5x5=64,\n","              filters_pool=64)\n","\n","x = inception(x,\n","              filters_1x1=112,\n","              filters_3x3_reduce=144,\n","              filters_3x3=288,\n","              filters_5x5_reduce=32,\n","              filters_5x5=64,\n","              filters_pool=64)\n","\n","aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n","aux2 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n","aux2 = layers.Flatten()(aux2)\n","aux2 = layers.Dense(1024, activation='relu')(aux2)\n","aux2 = layers.Dropout(0.7)(aux2)\n","aux2 = layers.Dense(10, activation='softmax')(aux2)\n","\n","x = inception(x,\n","              filters_1x1=256,\n","              filters_3x3_reduce=160,\n","              filters_3x3=320,\n","              filters_5x5_reduce=32,\n","              filters_5x5=128,\n","              filters_pool=128)\n","\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","\n","x = inception(x,\n","              filters_1x1=256,\n","              filters_3x3_reduce=160,\n","              filters_3x3=320,\n","              filters_5x5_reduce=32,\n","              filters_5x5=128,\n","              filters_pool=128)\n","\n","x = inception(x,\n","              filters_1x1=384,\n","              filters_3x3_reduce=192,\n","              filters_3x3=384,\n","              filters_5x5_reduce=48,\n","              filters_5x5=128,\n","              filters_pool=128)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","\n","x = layers.Dropout(0.4)(x)\n","out = layers.Dense(200, activation='softmax')(x)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzIFlLP9LcLQ","executionInfo":{"status":"ok","timestamp":1671710402160,"user_tz":-60,"elapsed":548,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["model = Model(inputs = inp, outputs = [out, aux1, aux2])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJjdIxC1aWwO","executionInfo":{"status":"ok","timestamp":1671710441472,"user_tz":-60,"elapsed":536,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["model.compile(optimizer='adam', loss=[losses.categorical_crossentropy, losses.categorical_crossentropy, losses.categorical_crossentropy], loss_weights=[1, 0.3, 0.3], metrics=['accuracy'])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"VofnKKKoauYX"},"source":["history = model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_val, [y_val, y_val, y_val]), batch_size=64, epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53UluuOE5TX_","executionInfo":{"status":"aborted","timestamp":1671710219449,"user_tz":-60,"elapsed":4,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["fig, axs = plt.subplots(2, 1, figsize=(15,15))\n","\n","axs[0].plot(history.history['loss'])\n","axs[0].plot(history.history['val_loss'])\n","axs[0].title.set_text('Training Loss vs Validation Loss')\n","axs[0].set_xlabel('Epochs')\n","axs[0].set_ylabel('Loss')\n","axs[0].legend(['Train','Val'])\n","\n","axs[1].plot(history.history['dense_4_accuracy'])\n","axs[1].plot(history.history['val_dense_4_accuracy'])\n","axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n","axs[1].set_xlabel('Epochs')\n","axs[1].set_ylabel('Accuracy')\n","axs[1].legend(['Train', 'Val'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNbFiTZW5dQ7","executionInfo":{"status":"aborted","timestamp":1671710219450,"user_tz":-60,"elapsed":1,"user":{"displayName":"Victor Daube","userId":"03006392672859710655"}}},"source":["model.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[]}]}